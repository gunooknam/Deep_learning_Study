{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO를 이해하자 v1\n",
    "You Only Look Once: Unified, Real-Time Object Detection https://arxiv.org/pdf/1506.02640.pdf\n",
    "\n",
    "<img src=\"img/yologo.png\" width=\"30%\">\n",
    "\n",
    "코드 출처 : https://github.com/pbcquoc/yolo <br>\n",
    "관련 블로그 : https://pbcquoc.github.io/yolo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "from tensorflow.contrib.slim.nets import vgg\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 그리드에 대해서 2개씩의 앵커박스를 예측한다.\n",
    "\n",
    "\n",
    "전체 그리드는 7x7\n",
    "\n",
    "\n",
    "우리는  (nbox + 4* nbox + nclass) 차원을 가진 벡터를 추측해야 한다.\n",
    "\n",
    "그래서 2개의 상자, 3개의 클래스인 경우\n",
    "\n",
    "7x7x13 3차원의 행렬을 만든다.\n",
    "\n",
    "\n",
    "object1 | object2 | offset x1 | offset y1 | width1 | height2 | offset x1 | offset y1 | width1 | height2 | 클래스1, 클래스2 클래스 3... |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_size = 7\n",
    "\n",
    "box_per_cell = 2\n",
    "img_size = 224\n",
    "\n",
    "classes = {'circle': 0, 'triangle':1, 'rectangle': 2}\n",
    "nclass = len(classes)\n",
    "\n",
    "\n",
    "box_scale = 5.0\n",
    "noobject_scale = 0.5\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 셋 로드 \n",
    "우리는 크기가 각각 224x224 인 25k 개의 데이터 샘플을 가지고 있으며 json 파일에는 객체가 들어있는 \n",
    "경계 상자의 배치에 해당하는 객체 세트를 비롯하여 이미지 이미지가 포함되어 있습니다.\n",
    "\n",
    "데이터를 준비하려면 모든 이미지를 메모리에로드하고 경계 상자의 레벨 정보를 위의 레이블 정보로 바꿔야합니다.\n",
    "\n",
    "vector를 만들 것인데 우리가 다루기 위한 벡터를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    labels = json.load(open('train/train/labels.json'))\n",
    "    N = len(labels)\n",
    "    X = np.zeros((N, img_size, img_size, 3), dtype='uint8')\n",
    "    y = np.zeros((N, cell_size, cell_size, 5 + nclass))\n",
    "    for idx, label in enumerate(labels):\n",
    "        img = cv2.imread(\"train/train/{}.png\".format(idx))\n",
    "        X[idx] = img\n",
    "        for box in label['boxes']:\n",
    "            x1, y1 = box['x1'], box['y1']\n",
    "            x2, y2 = box['x2'], box['y2']\n",
    "            # 객체 라벨의 one-hot vector \n",
    "            cl = [0]*len(classes)         # 길이 클래스개를 만들고 \n",
    "            \n",
    "            cl[classes[box['class']]] = 1 #  \n",
    "            \n",
    "            x_center, y_center, w, h = (x1+x2)/2.0, (y1+y2)/2.0, x2-x1, y2-y1\n",
    "            x_idx, y_idx = int(x_center/img_size*cell_size), int(y_center/img_size*cell_size)\n",
    "            \n",
    "            y[idx, y_idx, x_idx]= 1, x_center, y_center, w, h, *cl \n",
    "                                     # 배열의 원소를 넣어줄 때 *을 붙인다.\n",
    "                                     # cl은 ground truth의 onehot이다.\n",
    "                                     # 해석해 보자면 \n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 / unknown"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "url ='https://docs.google.com/uc?export=download&id=1rZufpopTpqjeMNGD1bHgORTw7WF4mmug'\n",
    "filename = wget.download(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.zip 압축 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 사각형에 대해 어떤 정보를 예측해야하는지, 다음 요구 사항에 따라 적절한 모양으로 출력을 제공하는 \n",
    "CNN 모델을 만드는 것이 중요하다. \n",
    "\n",
    "즉, gridsize x gridsize x (nbox + 4*nbox +nclass) \n",
    "\n",
    "gridsize의 경우, 예를 들어 7x7은 각각 2개의 상자로 예측하여 CNN 모델에서 7x7x13 모양을 출력하는 데 필요한 모든 개체가 3가지 유형이다.\n",
    "\n",
    "YOLO는 선형 회구를 사용하여 각 사각형의 정보를 예측한다. \n",
    "따라서 마지막 레이어에서는 활성화 함수를 전혀 사용하지 않는다. 448x448의 입력 이미지로 CNN 모델은 2x2 크기의 6개의 max pooling을 사용하여 출력 크기에서 이미지의 크기의 64배를 7x7로 줄인다. 동시에 마지막 층의 전체 연결을 바닥을 사용하는 대신 7x7x13의 출력 모양을 쉽게 만들 수 있도록 1x1 conv레이어로 13개의 feature map을 대체한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16(inputs, is_training):\n",
    "    '''\n",
    "    args:\n",
    "        inputs : 5-D tensor [batch_size, width, height, 3]\n",
    "    return:\n",
    "        iou    : 4-D tensor [batch_size, 7 , 7, 5*nbox + nclass]\n",
    "    '''\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        with tf.variable_scope(\"vgg_16\"):\n",
    "            with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "                net = slim.repeat(inputs, 2, slim.conv2d, 16, [3,3] ,scope='conv1')\n",
    "                net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "                net = slim.repeat(net,   2, slim.conv2d, 32, [3,3], scope='conv2')\n",
    "                net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "                net = slim.repeat(net,   2, slim.conv2d, 64, [3, 3], scope='conv3')\n",
    "                net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "                net = slim.repeat(net,   2, slim.conv2d, 128, [3, 3], scope='conv4')\n",
    "                net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "                net = slim.repeat(net,   2, slim.conv2d, 256, [3, 3], scope='conv5')\n",
    "                net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "                net = slim.conv2d(net, 512, [1,1], scope='fc6')\n",
    "                # 마지막층엔 Activation 없다. \n",
    "                net = slim.conv2d(net, 13, [1,1], activation_fn=None, scope='fc7')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOU 기능\n",
    "\n",
    "![iou](img/iou.png)\n",
    "\n",
    "IOU는 모델의 성능 평가를 위한 기준이다. Union 분의 Intersection으로 구한다.\n",
    "\n",
    "=> intersection / Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2, scope='iou'):\n",
    "    \"\"\"calculate ious\n",
    "    Args:\n",
    "      boxes1: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4] \n",
    "              마지막 4의 정체 ====> (x_center, y_center, w, h)\n",
    "              \n",
    "      boxes2: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4] \n",
    "              마지막 4의 정체 ====> (x_center, y_center, w, h)\n",
    "    Return:\n",
    "      iou:    4-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        # transform(x_center, y_center, w, h) to (x1, y1, x2, y2)\n",
    "        # spread 연산 \n",
    "        \n",
    "        # center, width, height로 역으로 좌표로 변환\n",
    "        # spread 연산을 사용한다. \n",
    "        boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,  # 이건 벡터다. x1들의 집합이 된다.\n",
    "                             boxes1[..., 1] - boxes1[..., 3] / 2.0,  # 이건 벡터다. y1들의 집합이 된다.\n",
    "                             boxes1[..., 0] + boxes1[..., 2] / 2.0,  # 이건 벡터다. x2들의 집합이 된다.\n",
    "                             boxes1[..., 1] + boxes1[..., 3] / 2.0], # 이건 벡터다. y2들의 집합이 된다.\n",
    "                            axis=-1)\n",
    "        \n",
    "        boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
    "                             boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
    "                             boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
    "                             boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
    "                            axis=-1) \n",
    "        \n",
    "        # calculate the left up point & right down point\n",
    "        # box1 (x1, y1) \n",
    "        # box2 (x2, y2) 와 비교 \n",
    "        \n",
    "        # 각 엘리먼트에서 하나씩 뽑아서 노란 사각형의 left_up 좌표 구함 \n",
    "        left_up    = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])\n",
    "        # 노란 사각형의 right_down 좌표\n",
    "        right_down = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])\n",
    "        \n",
    "        # intersection 노랑색 사각형 넓이 구하기\n",
    "        intersection = tf.maximum(0.0, right_down-left_up)\n",
    "        inter_square = intersection[..., 0] * intersection[..., 1]\n",
    "        \n",
    "        # calculate the boxes1 square and boxes2 square\n",
    "        # square1 =>  width*height\n",
    "        square1 = boxes1[..., 2]*boxes1[..., 3]\n",
    "        square2 = boxes2[..., 2]*boxes2[..., 3]\n",
    "        union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
    "        \n",
    "    return tf.clip_by_value(inter_square / union_square, 0.0, 1.0 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "\n",
    "yolo는 multi loss function을 사용하며 loss function들은 다음과 같다.\n",
    "\n",
    "* classfication loss \n",
    "* localization loss\n",
    "* confidence loss\n",
    "\n",
    "훈련 중에 모델은 물체가 포함된 사각형을 볼 것이다. 해당 개체의 올바른 클래스 점수를 올려야 한다.\n",
    "그런 다음 해당 상자를 보고 예상되는 2개의 상자에서 가장 좋은 경계 상자를 찾는다. 경계 상자의 지역화 점수를 높이고 경계 상자 정보를 레이블과 비슷하게 변경! <br>\n",
    "물체를 포함하지 않는 경우 실뢰도 낮추고 이 사각형의 점수는 don't care\n",
    "\n",
    "\n",
    "1. Classification Loss\n",
    "이 Loss는 예측된 레이블과 올바른 레이블 사이에 제곱된 오차이다.\n",
    "\n",
    "![closs](img/closs.png)\n",
    "\n",
    "p'i(c) 모델이 예측하는 해당 사각형에서 클래스 c에 해당하는 확률\n",
    "\n",
    "# Localization Loss\n",
    "\n",
    "![lloss](img/lloss.png)\n",
    "\n",
    "\n",
    "# Confidence Loss\n",
    "![cfloss](img/cfloss.png)\n",
    "\n",
    "# Total Loss\n",
    "![tloss](img/tloss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_layer(predicts, labels, scope='loss_layer'):\n",
    "    \n",
    "    \"\"\"calculate loss function\n",
    "    Args:\n",
    "      predicts: 4-D tensor [batch_size, 7, 7, 5*nbox+n_class] \n",
    "      labels: 4-D tensor [batch_size, 7, 7, 5+n_class]\n",
    "    Return:\n",
    "      loss: scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        offset = np.transpose( np.reshape(np.array( [np.arange(cell_size)] * cell_size * box_per_cell),\n",
    "                               (box_per_cell, cell_size, cell_size)),\n",
    "                               (1, 2, 0 ) )\n",
    "        \n",
    "        offset = offset[None, :]\n",
    "        # (None, cell_size, cell_size, box_per_cell)\n",
    "        \n",
    "        offset = tf.constant(offset, dtype= tf.float32)\n",
    "        offset_tran = tf.transpose(offset, (0,2,1,3))\n",
    "        \n",
    "        # 사각형 내 예측 벡터의 첫 번째 요소는 confidence score이다.\n",
    "        predict_object = predicts[..., :box_per_cell]\n",
    "        \n",
    "        # bound box 및 width, height 예측\n",
    "        predict_box_offset = tf.reshape( predicts[..., box_per_cell:5*box_per_cell],\n",
    "                                         (-1, cell_size, cell_size, box_per_cell, 4) )\n",
    "        \n",
    "        # 마지막 요소는 객체 클래스의 예측이다.\n",
    "        predict_class = predicts[..., 5*box_per_cell:]\n",
    "        \n",
    "        # 오프셋 위치를 (0 ~ 1) 좌표 노말라이즈로 한다.\n",
    "        predict_normalized_box = tf.stack(\n",
    "                                [ (predict_box_offset[..., 0] + offset) / cell_size,\n",
    "                                  (predict_box_offset[..., 1] + offset_tran) / cell_size, \n",
    "                                  tf.square(predict_box_offset[..., 2]),\n",
    "                                  tf.square(predict_box_offset[..., 3]) ], axis=-1)\n",
    "        \n",
    "        # 대응하는 라벨을 얻는다. \n",
    "        true_object = labels[..., :1]\n",
    "        true_box = tf.reshape(labels[..., 1:5], (-1, cell_size, cell_size, 1, 4))\n",
    "        \n",
    "        # 픽셀 좌표를 단락 (0, 1)로 정규화하려면 img_size 224로 나눈다.\n",
    "        true_normalized_box = tf.tile(true_box, (1, 1, 1, box_per_cell, 1))/img_size\n",
    "        true_class = labels[...,5:]\n",
    "        \n",
    "        # 레이블에서 offset 위치 계산\n",
    "        true_box_offset = tf.stack(\n",
    "                                    [true_normalized_box[..., 0] * cell_size - offset,\n",
    "                                     true_normalized_box[..., 1] * cell_size - offset_tran,\n",
    "                                    tf.sqrt(true_normalized_box[..., 2]),\n",
    "                                    tf.sqrt(true_normalized_box[...,3])],\n",
    "                            axis=-1)\n",
    "        \n",
    "        # iou count\n",
    "        predict_iou = compute_iou(true_normalized_box, predict_normalized_box)\n",
    "        \n",
    "        # 마스크는 정사각형을 포함하는 객체의 위치를 포함\n",
    "        object_mask = tf.reduce_max(predict_iou, 3, keepdims=True)\n",
    "        \n",
    "        # 모니터할 측정 항목\n",
    "        iou_metric = tf.reduce_mean(tf.reduce_sum(object_mask, axis=[1,2,3])/ tf.reduce_sum(true_object,\n",
    "                                                                                          axis=[1,2,3]))\n",
    "\n",
    "        object_mask = tf.cast((predict_iou>=object_mask), tf.float32)* true_object\n",
    "        noobject_mask = tf.ones_like(object_mask) - object_mask\n",
    "        \n",
    "        ## class loss \n",
    "        class_delta = true_object*(predict_class - true_class)\n",
    "        class_loss = tf.reduce_mean(tf.reduce_sum(tf.square(class_delta), axis=[1,2,3]), name='class_loss')\n",
    "        \n",
    "        ## object loss\n",
    "        object_delta = object_mask*(predict_object - predict_iou)\n",
    "        object_loss = tf.reduce_mean(tf.reduce_sum(tf.square(object_delta), axis=[1,2,3]), name='object_loss')\n",
    "        \n",
    "        ## noobject loss\n",
    "        noobject_delta = noobject_mask*predict_object \n",
    "        noobject_loss = tf.reduce_mean(tf.reduce_sum(tf.square(noobject_delta), axis=[1,2,3]), name='noobject_loss')\n",
    "        \n",
    "        ## coord loss\n",
    "        box_mask  = tf.expand_dims(object_mask, 4)\n",
    "        box_delta = box_mask*(predict_box_offset - true_box_offset)\n",
    "        box_loss  = tf.reduce_mean(tf.reduce_sum(tf.square(box_delta), axis=[1,2,3]), name='box_loss')\n",
    "        \n",
    "        loss = 0.5*class_loss + object_loss + 0.1*noobject_loss + 10*box_loss\n",
    "        \n",
    "        return loss, iou_metric, predict_object, predict_class, predict_normalized_box\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그래프 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    images      = tf.placeholder(\"float\", [None, img_size,  img_size,  3], name=\"input\")\n",
    "    labels      = tf.placeholder(\"float\", [None, cell_size, cell_size, 8], name=\"label\")\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "    logits = vgg16(images, is_training)\n",
    "    loss, iou_metric, predict_object, predict_class, predict_normalized_box = loss_layer(logits, labels)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    train_op  = optimizer.minimize(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - running_time: 70s - train_loss: 0.769 - train_iou: 0.548 - val_loss: 0.739 - val_iou: 0.555\n",
      "epoch: 1 - running_time: 69s - train_loss: 0.343 - train_iou: 0.623 - val_loss: 0.394 - val_iou: 0.598\n",
      "epoch: 2 - running_time: 70s - train_loss: 0.267 - train_iou: 0.630 - val_loss: 0.278 - val_iou: 0.629\n",
      "epoch: 3 - running_time: 70s - train_loss: 0.204 - train_iou: 0.688 - val_loss: 0.229 - val_iou: 0.645\n",
      "epoch: 4 - running_time: 69s - train_loss: 0.189 - train_iou: 0.671 - val_loss: 0.195 - val_iou: 0.656\n",
      "epoch: 5 - running_time: 69s - train_loss: 0.166 - train_iou: 0.730 - val_loss: 0.182 - val_iou: 0.720\n",
      "epoch: 6 - running_time: 71s - train_loss: 0.143 - train_iou: 0.700 - val_loss: 0.168 - val_iou: 0.730\n",
      "epoch: 7 - running_time: 70s - train_loss: 0.137 - train_iou: 0.724 - val_loss: 0.148 - val_iou: 0.717\n",
      "epoch: 8 - running_time: 69s - train_loss: 0.127 - train_iou: 0.752 - val_loss: 0.144 - val_iou: 0.707\n",
      "epoch: 9 - running_time: 70s - train_loss: 0.153 - train_iou: 0.695 - val_loss: 0.135 - val_iou: 0.735\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 새미이지를 테스트할 때 모델의 weight를 저장하는 Saver\n",
    "    saver = tf.train.Saver(max_to_keep=1)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        for batch in range(len(X_train)//batch_size):\n",
    "            # adam에 따라 optimization \n",
    "            X_batch = X_train[batch*batch_size: (batch+1)*batch_size]\n",
    "            y_batch = y_train[batch*batch_size: (batch+1)*batch_size]\n",
    "            train_total_loss, train_iou_m ,_ = sess.run([loss, iou_metric, train_op], \n",
    "                                                        {images:X_batch,\n",
    "                                                         labels:y_batch,\n",
    "                                                         is_training:True})\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # 이부분은 valiation loss를 확인\n",
    "        val_loss   = []\n",
    "        val_iou_ms = []\n",
    "        for batch in range(len(X_test)//batch_size):\n",
    "            val_X_batch = X_test[ batch*batch_size : (batch+1)*batch_size]\n",
    "            val_y_batch = y_test[ batch*batch_size : (batch+1)*batch_size]\n",
    "            total_val_loss, val_iou_m, val_predict_object, val_predict_class, val_predict_normalized_box = sess.run([loss, iou_metric, predict_object, predict_class, predict_normalized_box], \n",
    "                                                 {images:val_X_batch, labels:val_y_batch, is_training:False})\n",
    "            \n",
    "            val_loss.append(total_val_loss)\n",
    "            val_iou_ms.append(val_iou_m)\n",
    "            \n",
    "        \n",
    "        saver.save(sess, './model/yolo', global_step=epoch)\n",
    "        print('epoch: {} - running_time: {:.0f}s - train_loss: {:.3f} - train_iou: {:.3f} - val_loss: {:.3f} - val_iou: {:.3f}'.format(epoch, end_time - start_time, train_total_loss, train_iou_m, np.mean(val_loss), np.mean(val_iou_ms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction 결과 표시\n",
    "\n",
    "조건에 맞지 않는 모든 상자 필터링, 개체 포함 안함 <br>\n",
    "Non Maximum supression - 여러개의 겹침 상자 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    \"\"\" tính iou bằng numpy \n",
    "    Args:\n",
    "      box1: [center_x, center_y, w, h] \n",
    "      box2: [center_x, center_y, w, h] \n",
    "    Return:\n",
    "      iou: iou\n",
    "    \"\"\"\n",
    "    tb = min(box1[0] + 0.5 * box1[2], box2[0] + 0.5 * box2[2]) - \\\n",
    "        max(box1[0] - 0.5 * box1[2], box2[0] - 0.5 * box2[2])\n",
    "    lr = min(box1[1] + 0.5 * box1[3], box2[1] + 0.5 * box2[3]) - \\\n",
    "        max(box1[1] - 0.5 * box1[3], box2[1] - 0.5 * box2[3])\n",
    "    inter = 0 if tb < 0 or lr < 0 else tb * lr\n",
    "    return inter / (box1[2] * box1[3] + box2[2] * box2[3] - inter)\n",
    "    \n",
    "def interpret_output(predict_object, predict_class, predict_normalized_box):\n",
    "    # 노말라이즈 된거에 인풋 사이즈 곱\n",
    "    predict_box= predict_normalized_box*img_size\n",
    "    predict_object = np.expand_dims(predict_object, axis=-1)\n",
    "    predict_class = np.expand_dims(predict_class, axis=-2)\n",
    "    \n",
    "    #\n",
    "    class_probs = predict_object*predict_class\n",
    "    \n",
    "    # 레이어를 포함할 경계 상자 유지 >= 0.2\n",
    "    filter_mat_probs = np.array(class_probs >= 0.2, dtype='bool')\n",
    "    filter_mat_boxes = np.nonzero(filter_mat_probs)\n",
    "    boxes_filtered = predict_box[filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\n",
    "    class_probs_filtered = class_probs[filter_mat_probs]\n",
    "    \n",
    "    # 클래스 인덱스를 선택해서 각 바운드 박스의 경계 레이어 결정 \n",
    "    classes_num_filtered = np.argmax(\n",
    "        filter_mat_probs, axis=3)[\n",
    "        filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\n",
    "\n",
    "    # 가능성이 가장 높은 확률을 예측하는 바운드 박스로 남김\n",
    "    argsort = np.array(np.argsort(class_probs_filtered))[::-1]\n",
    "    boxes_filtered = boxes_filtered[argsort]\n",
    "    class_probs_filtered = class_probs_filtered[argsort]\n",
    "    classes_num_filtered = classes_num_filtered[argsort]\n",
    "\n",
    "    #  non-maximun suppression 계산\n",
    "    for i in range(len(boxes_filtered)):\n",
    "        if class_probs_filtered[i] == 0:\n",
    "            continue\n",
    "        for j in range(i + 1, len(boxes_filtered)):\n",
    "            if iou(boxes_filtered[i], boxes_filtered[j]) > 0.5:\n",
    "                class_probs_filtered[j] = 0.0\n",
    "                \n",
    "    # 마지막 단계의 필터로 논맥시점으로 오버랩 제거\n",
    "    filter_iou = np.array(class_probs_filtered > 0.0, dtype='bool')\n",
    "    boxes_filtered = boxes_filtered[filter_iou]\n",
    "    class_probs_filtered = class_probs_filtered[filter_iou]\n",
    "    classes_num_filtered = classes_num_filtered[filter_iou]\n",
    "\n",
    "    result = []\n",
    "    for i in range(len(boxes_filtered)):\n",
    "        result.append(\n",
    "            [classes_num_filtered[i],\n",
    "             boxes_filtered[i][0],\n",
    "             boxes_filtered[i][1],\n",
    "             boxes_filtered[i][2],\n",
    "             boxes_filtered[i][3],\n",
    "             class_probs_filtered[i]])\n",
    "\n",
    "    return result\n",
    "\n",
    "def draw_result(img, result):\n",
    "    \"\"\" 예상되는 결과 표시\n",
    "    Args:\n",
    "      img: 이미지\n",
    "      result: 생성된 이미지 값    \n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,10), dpi=40)\n",
    "    img = np.pad(img, [(50,50), (50,50), (0,0)], mode='constant', constant_values=255)\n",
    "    for i in range(len(result)):\n",
    "        x = int(result[i][1])+50\n",
    "        y = int(result[i][2])+50\n",
    "        w = int(result[i][3] / 2)\n",
    "        h = int(result[i][4] / 2)\n",
    "        cv2.rectangle(img, (x - w, y - h), (x + w, y + h), (231, 76, 60), 2)\n",
    "        cv2.rectangle(img, (x - w, y - h - 20),\n",
    "                      (x -w + 50, y - h), (46, 204, 113), -1)\n",
    "        cv2.putText(\n",
    "            img, '{} : {:.2f}'.format(result[i][0] ,result[i][5]),\n",
    "            (x - w + 5, y - h - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.3,\n",
    "            (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 15\n",
    "result = interpret_output(val_predict_object[img_idx], val_predict_class[img_idx], val_predict_normalized_box[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_result(val_X_batch[img_idx]*255, result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
